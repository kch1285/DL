{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "train_data_mnist = datasets.MNIST('./datasets', train = True, download = True, transform = transforms.ToTensor())\n",
    "test_data_mnist = datasets.MNIST('./datasets', train = False, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "print(len(train_data_mnist))\n",
    "train_set, val_set = torch.utils.data.random_split(train_data_mnist, [50000, 10000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "dev_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_mnist, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        n_channels_1 = 6\n",
    "        n_channels_2 = 16\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, n_channels_1, kernel_size = 3, stride = 1), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_channels_1, n_channels_2, kernel_size = 5, stride = 1), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(4 * 4 * n_channels_2, 120, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            self.fc3, \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p = 1 - self.keep_prob))\n",
    "        \n",
    "        self.fc4 = torch.nn.Linear(120, 80, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc4, \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p = 1 - self.keep_prob))\n",
    "        \n",
    "        self.fc5 = torch.nn.Linear(80, 10, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
    "        \n",
    "        #Softmax is included in nn.CrossEntropyLoss\n",
    "        \n",
    "        \n",
    "def forward(self, x):\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = out.view(out.size(0), -1) #Flatten them for FC\n",
    "            \n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "        \n",
    "    out = self.fc5(out)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader, model):\n",
    "    model.eval()\n",
    "    n_predict = 0\n",
    "    n_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm.tqdm(data_loader):\n",
    "            y_hat = model(X)\n",
    "            y_hat.argmax()\n",
    "            \n",
    "            _, predicted = torch.max(y_hat, 1)\n",
    "        \n",
    "            n_predict += len(predicted)\n",
    "            n_correct += (Y == predicted).sum()\n",
    "            \n",
    "    accuracy = n_correct / n_predict\n",
    "    print(f\"Accuracy : {accuracy} ()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b1527cfb232c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_epochs = 5\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    cost = 0\n",
    "    n_batches = 0\n",
    "    for X, Y in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = criterion(y_hat, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    cost /= n_batches\n",
    "    print('[Epoch : {:>4}] cost = {:>.9}'.format(epoch + 1, cost))\n",
    "    print('Dev')\n",
    "    test(dev_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
